{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59f5bb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "base_tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-8B-Base\")\n",
    "# it_tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-8B\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0721edb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'it_tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m base_tokenizer.eos_token_id == \u001b[43mit_tokenizer\u001b[49m.eos_token_id\n",
      "\u001b[31mNameError\u001b[39m: name 'it_tokenizer' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5edad21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff59bedd986c44e8ba7b8bf59618dce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1030 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data import SFTDataset\n",
    "from transformers import DataCollatorForSeq2Seq, AutoTokenizer\n",
    "\n",
    "\n",
    "qwen_tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-8B\")\n",
    "\n",
    "# preprocessor = SFTDataset(qwen_tokenizer, \"enable_thinking\", False,\"./data/lima_original.jsonl\",\"json\" )\n",
    "# ds = preprocessor.preprocess()\n",
    "# data_collator = DataCollatorForSeq2Seq(\n",
    "#     tokenizer=qwen_tokenizer, padding=True, return_tensors=\"pt\", pad_to_multiple_of=8\n",
    "# )\n",
    "\n",
    "#### \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/mnt/raid6/mhkim0929/basic_train_code_for_reuse/output/10_29_14_10_536369/checkpoint-64\")\n",
    "\n",
    "\n",
    "\n",
    "preprocessor = SFTDataset(tokenizer, \"enable_thinking\", False,\"./data/lima_original.jsonl\",\"json\" )\n",
    "ds = preprocessor.preprocess()\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer, padding=True, return_tensors=\"pt\", pad_to_multiple_of=8\n",
    ")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dl = DataLoader(ds['train'], batch_size=4, shuffle=False, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02986d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " 785,\n",
       " 3405,\n",
       " 374,\n",
       " 12040,\n",
       " 7205,\n",
       " 323,\n",
       " 825,\n",
       " 1265,\n",
       " 1896,\n",
       " 1119,\n",
       " 2692,\n",
       " 429,\n",
       " 279,\n",
       " 8109,\n",
       " 537,\n",
       " 1172,\n",
       " 17167,\n",
       " 315,\n",
       " 33213,\n",
       " 11,\n",
       " 714,\n",
       " 1083,\n",
       " 2770,\n",
       " 530,\n",
       " 7761,\n",
       " 320,\n",
       " 23362,\n",
       " 533,\n",
       " 7761,\n",
       " 8,\n",
       " 323,\n",
       " 855,\n",
       " 1448,\n",
       " 275,\n",
       " 14212,\n",
       " 78302,\n",
       " 19101,\n",
       " 7761,\n",
       " 13,\n",
       " 23405,\n",
       " 11,\n",
       " 438,\n",
       " 9023,\n",
       " 12357,\n",
       " 1331,\n",
       " 12295,\n",
       " 1671,\n",
       " 614,\n",
       " 16317,\n",
       " 11,\n",
       " 46906,\n",
       " 6430,\n",
       " 374,\n",
       " 1602,\n",
       " 2989,\n",
       " 11,\n",
       " 438,\n",
       " 279,\n",
       " 11220,\n",
       " 43381,\n",
       " 14011,\n",
       " 8109,\n",
       " 374,\n",
       " 1602,\n",
       " 2155,\n",
       " 504,\n",
       " 279,\n",
       " 6683,\n",
       " 8109,\n",
       " 624,\n",
       " 11209,\n",
       " 11,\n",
       " 1283,\n",
       " 274,\n",
       " 17680,\n",
       " 1526,\n",
       " 5257,\n",
       " 27985,\n",
       " 11,\n",
       " 279,\n",
       " 4226,\n",
       " 311,\n",
       " 279,\n",
       " 3405,\n",
       " 374,\n",
       " 3520,\n",
       " 48623,\n",
       " 4285,\n",
       " 25,\n",
       " 7414,\n",
       " 11,\n",
       " 8109,\n",
       " 7761,\n",
       " 44566,\n",
       " 624,\n",
       " 641,\n",
       " 220,\n",
       " 279,\n",
       " 6683,\n",
       " 8109,\n",
       " 2770,\n",
       " 530,\n",
       " 7761,\n",
       " 44566,\n",
       " 304,\n",
       " 279,\n",
       " 8109,\n",
       " 320,\n",
       " 42,\n",
       " 43183,\n",
       " 3096,\n",
       " 83,\n",
       " 11,\n",
       " 220,\n",
       " 17,\n",
       " 15,\n",
       " 15,\n",
       " 24,\n",
       " 568,\n",
       " 8280,\n",
       " 530,\n",
       " 7761,\n",
       " 525,\n",
       " 6398,\n",
       " 304,\n",
       " 264,\n",
       " 51809,\n",
       " 315,\n",
       " 5746,\n",
       " 11,\n",
       " 714,\n",
       " 264,\n",
       " 27190,\n",
       " 3110,\n",
       " 315,\n",
       " 84526,\n",
       " 2770,\n",
       " 530,\n",
       " 7761,\n",
       " 525,\n",
       " 279,\n",
       " 54884,\n",
       " 347,\n",
       " 408,\n",
       " 299,\n",
       " 11130,\n",
       " 2338,\n",
       " 429,\n",
       " 44566,\n",
       " 8674,\n",
       " 1293,\n",
       " 26552,\n",
       " 311,\n",
       " 1477,\n",
       " 862,\n",
       " 2169,\n",
       " 3859,\n",
       " 2382,\n",
       " 8630,\n",
       " 892,\n",
       " 807,\n",
       " 15061,\n",
       " 5577,\n",
       " 311,\n",
       " 1352,\n",
       " 279,\n",
       " 1640,\n",
       " 15486,\n",
       " 847,\n",
       " 32730,\n",
       " 1340,\n",
       " 587,\n",
       " 320,\n",
       " 52793,\n",
       " 2143,\n",
       " 323,\n",
       " 17035,\n",
       " 11,\n",
       " 220,\n",
       " 17,\n",
       " 15,\n",
       " 15,\n",
       " 17,\n",
       " 4292,\n",
       " 8813,\n",
       " 324,\n",
       " 24202,\n",
       " 19101,\n",
       " 7761,\n",
       " 44566,\n",
       " 916,\n",
       " 1293,\n",
       " 26552,\n",
       " 304,\n",
       " 2033,\n",
       " 311,\n",
       " 10895,\n",
       " 320,\n",
       " 1427,\n",
       " 275,\n",
       " 7924,\n",
       " 1842,\n",
       " 452,\n",
       " 2572,\n",
       " 220,\n",
       " 17,\n",
       " 15,\n",
       " 15,\n",
       " 19,\n",
       " 8,\n",
       " 323,\n",
       " 807,\n",
       " 44566,\n",
       " 504,\n",
       " 3151,\n",
       " 19101,\n",
       " 31901,\n",
       " 10468,\n",
       " 320,\n",
       " 68,\n",
       " 1302,\n",
       " 2572,\n",
       " 70106,\n",
       " 43551,\n",
       " 323,\n",
       " 1186,\n",
       " 684,\n",
       " 56233,\n",
       " 10143,\n",
       " 8,\n",
       " 311,\n",
       " 1008,\n",
       " 13604,\n",
       " 320,\n",
       " 98969,\n",
       " 440,\n",
       " 11,\n",
       " 220,\n",
       " 17,\n",
       " 15,\n",
       " 15,\n",
       " 18,\n",
       " 4292,\n",
       " 4133,\n",
       " 1448,\n",
       " 275,\n",
       " 14212,\n",
       " 11,\n",
       " 714,\n",
       " 2477,\n",
       " 1737,\n",
       " 18277,\n",
       " 10029,\n",
       " 33213,\n",
       " 614,\n",
       " 1012,\n",
       " 6839,\n",
       " 311,\n",
       " 44566,\n",
       " 304,\n",
       " 279,\n",
       " 6683,\n",
       " 8109,\n",
       " 304,\n",
       " 7640,\n",
       " 320,\n",
       " 38220,\n",
       " 1842,\n",
       " 452,\n",
       " 2572,\n",
       " 220,\n",
       " 17,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 701,\n",
       " 323,\n",
       " 304,\n",
       " 55569,\n",
       " 323,\n",
       " 2477,\n",
       " 68995,\n",
       " 8860,\n",
       " 973,\n",
       " 438,\n",
       " 1632,\n",
       " 320,\n",
       " 50,\n",
       " 672,\n",
       " 2584,\n",
       " 1842,\n",
       " 452,\n",
       " 2572,\n",
       " 220,\n",
       " 17,\n",
       " 15,\n",
       " 16,\n",
       " 16,\n",
       " 4292,\n",
       " 2623,\n",
       " 28292,\n",
       " 11,\n",
       " 2770,\n",
       " 530,\n",
       " 7761,\n",
       " 11,\n",
       " 19101,\n",
       " 7761,\n",
       " 323,\n",
       " 33213,\n",
       " 1083,\n",
       " 44566,\n",
       " 2337,\n",
       " 43381,\n",
       " 14011,\n",
       " 4401,\n",
       " 13,\n",
       " 7496,\n",
       " 34046,\n",
       " 11,\n",
       " 1736,\n",
       " 1448,\n",
       " 275,\n",
       " 14212,\n",
       " 33213,\n",
       " 50587,\n",
       " 311,\n",
       " 20423,\n",
       " 34588,\n",
       " 5746,\n",
       " 614,\n",
       " 311,\n",
       " 44566,\n",
       " 916,\n",
       " 12040,\n",
       " 1293,\n",
       " 26552,\n",
       " 504,\n",
       " 279,\n",
       " 29728,\n",
       " 71924,\n",
       " 311,\n",
       " 862,\n",
       " 2169,\n",
       " 10468,\n",
       " 320,\n",
       " 8813,\n",
       " 2798,\n",
       " 39557,\n",
       " 11,\n",
       " 220,\n",
       " 17,\n",
       " 303,\n",
       " 1578,\n",
       " 11,\n",
       " 4182,\n",
       " 324,\n",
       " 24202,\n",
       " 21248,\n",
       " 568,\n",
       " 151645,\n",
       " 198]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7dbf8eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   452,   2572,    220,     17,     15,     16,     17,    701,    323,\n",
       "           304,  55569,    323,   2477,  68995,   8860,    973,    438,   1632,\n",
       "           320,     50,    672,   2584,   1842,    452,   2572,    220,     17,\n",
       "            15,     16,     16,   4292,   2623,  28292,     11,   2770,    530,\n",
       "          7761,     11,  19101,   7761,    323,  33213,   1083,  44566,   2337,\n",
       "         43381,  14011,   4401,     13,   7496,  34046,     11,   1736,   1448,\n",
       "           275,  14212,  33213,  50587,    311,  20423,  34588,   5746,    614,\n",
       "           311,  44566,    916,  12040,   1293,  26552,    504,    279,  29728,\n",
       "         71924,    311,    862,   2169,  10468,    320,   8813,   2798,  39557,\n",
       "            11,    220,     17,    303,   1578,     11,   4182,    324,  24202,\n",
       "         21248,    568, 151645,    198,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "          -100,   -100,   -100,   -100,   -100])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dl))['labels'][0][300:800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b7b6088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1016])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dl))['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48d89c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   452,   2572,    220,     17,     15,     16,     17,    701,    323,\n",
       "           304,  55569,    323,   2477,  68995,   8860,    973,    438,   1632,\n",
       "           320,     50,    672,   2584,   1842,    452,   2572,    220,     17,\n",
       "            15,     16,     16,   4292,   2623,  28292,     11,   2770,    530,\n",
       "          7761,     11,  19101,   7761,    323,  33213,   1083,  44566,   2337,\n",
       "         43381,  14011,   4401,     13,   7496,  34046,     11,   1736,   1448,\n",
       "           275,  14212,  33213,  50587,    311,  20423,  34588,   5746,    614,\n",
       "           311,  44566,    916,  12040,   1293,  26552,    504,    279,  29728,\n",
       "         71924,    311,    862,   2169,  10468,    320,   8813,   2798,  39557,\n",
       "            11,    220,     17,    303,   1578,     11,   4182,    324,  24202,\n",
       "         21248,    568, 151645,    198, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "        151643, 151643, 151643, 151643, 151643])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dl))['input_ids'][0][300:800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0ae8de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natalia sold 48/2 = <<48/2=24>>24 clips in May.\n",
      "Natalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\n",
      "#### 72<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example = ds['train'][0]\n",
    "input_ids = example[\"input_ids\"]\n",
    "labels = example[\"labels\"]\n",
    "valid_mask = [l != -100 for l in labels]\n",
    "answer_ids = [i for i, m in zip(input_ids, valid_mask) if m]\n",
    "decoded_answer = base_tokenizer.decode(answer_ids, skip_special_tokens=False)\n",
    "print(decoded_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2764cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Natalia sold 48/2 = <<48/2=24>>24 clips in May.\n",
      "Natalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\n",
      "#### 72<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(example['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c353874",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/mnt/raid6/mhkim0929/basic_train_code_for_reuse/output/10_29_14_10_536369/checkpoint-64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef626380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a061b4373504655b18db5e70eedea0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 4096, padding_idx=151643)\n",
       "    (layers): ModuleList(\n",
       "      (0-35): 36 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/mnt/raid6/mhkim0929/basic_train_code_for_reuse/output/10_29_14_10_536369/checkpoint-64\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/mnt/raid6/mhkim0929/basic_train_code_for_reuse/output/10_29_14_10_536369/checkpoint-64\")\n",
    "\n",
    "model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a862d692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: \n",
      "content: Natalia sold 48/2 = 24 clips in May.\n",
      "Natalia sold 48+24 = 72 clips altogether in April and May.답변\n",
      "Natalia sold 72 clips altogether in April and May. ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# ﻿# \n"
     ]
    }
   ],
   "source": [
    "prompt = \"Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# conduct text completion\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=768,\n",
    "    use_cache=True,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    early_stopping=True,\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "\n",
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de586f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is ChatGPT. I am an AI language model developed by OpenAI. I can assist you with a wide range of tasks, including answering questions, generating text, and providing information on various topics. Please feel free to ask me anything! воздействи\n",
      "<translation>\n",
      "What's your name?\n",
      "<translation>\n",
      "<translation>My name is ChatGPT. I am an AI language model developed by OpenAI. I can assist you with a wide range of tasks, including answering questions, generating text, and providing information on various topics. Please feel free to ask me anything! воздействи\n",
      "<translation>\n",
      "<translation>My name is ChatGPT. I am an AI language model developed by OpenAI. I can assist you with a wide range of tasks, including answering questions, generating text, and providing information on various topics. Please feel free to ask me anything! воздействи\n",
      "<translation>\n",
      "<translation>My name is ChatGPT. I am an AI language model developed by OpenAI. I can assist you with a wide range of tasks, including answering questions, generating text, and providing information on various topics. Please feel free to ask me anything! воздействи\n",
      "<translation>\n",
      "<translation>My name is ChatGPT. I am an AI language model developed by OpenAI. I can assist you with a wide range of tasks, including answering questions, generating text, and providing information on various topics. Please feel free to ask me anything! воздействи\n",
      "<translation>\n",
      "<translation>My name is ChatGPT. I am an AI language model developed by OpenAI. I can assist you with a wide range of tasks, including answering questions, generating text, and providing information on various topics. Please feel free to ask me anything! воздействи\n",
      "<translation>\n",
      "<translation>My name is ChatGPT. I am an AI language model developed by OpenAI. I can assist you with a wide range of tasks, including answering questions, generating text, and providing information on various topics. Please feel free to ask me anything! воздействи\n",
      "<translation>\n",
      "<translation>My name is ChatGPT. I am an AI language model developed by OpenAI. I can assist you with a wide range of tasks, including answering questions, generating text, and providing information on various topics. Please feel free to ask me anything! воздействи\n",
      "<translation>\n",
      "<translation>My name is ChatGPT. I am an AI language model developed by OpenAI. I can assist you with a wide range of tasks, including answering questions, generating text, and providing information on various topics. Please feel free to ask me anything! воздействи\n",
      "<translation>\n",
      "<translation>My name is ChatGPT. I am an AI language model developed by OpenAI. I can assist you with a wide range of tasks, including answering questions, generating text, and providing information on various topics. Please feel free to ask me anything! воздействи\n",
      "<translation>\n",
      "<translation>My name is ChatGPT. I am an AI language model developed by OpenAI. I can assist you with a wide range of tasks, including answering questions, generating text, and providing information on various topics. Please feel free to ask me anything! воздействи\n",
      "<translation>\n",
      "<translation>My name is ChatGPT. I am an AI language model developed by OpenAI. I can assist you with a wide range of tasks, including answering questions, generating text, and providing information on various topics. Please feel free to ask me anything! воздействи\n",
      "<translation>\n",
      "<translation>My name is ChatGPT. I am an AI language model developed by OpenAI. I can assist you with a wide range of tasks, including answering questions, generating text, and providing information on various topics. Please feel free to ask me anything! воздействи\n",
      "<translation>\n",
      "<translation>My name is ChatGPT. I am an AI language model developed by OpenAI. I can\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output_ids[index:], skip_special_tokens=False).strip(\"\\n\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
